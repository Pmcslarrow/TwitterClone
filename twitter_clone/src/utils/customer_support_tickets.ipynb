{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07fe898-0148-4dcb-9659-6a2a323866f6",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d985cae-619e-4f96-984e-4d9e34a5dbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Customer Email</th>\n",
       "      <th>Customer Age</th>\n",
       "      <th>Customer Gender</th>\n",
       "      <th>Product Purchased</th>\n",
       "      <th>Date of Purchase</th>\n",
       "      <th>Ticket Type</th>\n",
       "      <th>Ticket Subject</th>\n",
       "      <th>Ticket Description</th>\n",
       "      <th>Ticket Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Ticket Priority</th>\n",
       "      <th>Ticket Channel</th>\n",
       "      <th>First Response Time</th>\n",
       "      <th>Time to Resolution</th>\n",
       "      <th>Customer Satisfaction Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marisa Obrien</td>\n",
       "      <td>carrollallison@example.com</td>\n",
       "      <td>32</td>\n",
       "      <td>Other</td>\n",
       "      <td>GoPro Hero</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Product setup</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Pending Customer Response</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Social media</td>\n",
       "      <td>2023-06-01 12:15:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jessica Rios</td>\n",
       "      <td>clarkeashley@example.com</td>\n",
       "      <td>42</td>\n",
       "      <td>Female</td>\n",
       "      <td>LG Smart TV</td>\n",
       "      <td>2021-05-22</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Peripheral compatibility</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Pending Customer Response</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Chat</td>\n",
       "      <td>2023-06-01 16:45:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Christopher Robbins</td>\n",
       "      <td>gonzalestracy@example.com</td>\n",
       "      <td>48</td>\n",
       "      <td>Other</td>\n",
       "      <td>Dell XPS</td>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Network problem</td>\n",
       "      <td>I'm facing a problem with my {product_purchase...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Case maybe show recently my computer follow.</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social media</td>\n",
       "      <td>2023-06-01 11:14:38</td>\n",
       "      <td>2023-06-01 18:05:38</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticket ID        Customer Name              Customer Email  Customer Age  \\\n",
       "0          1        Marisa Obrien  carrollallison@example.com            32   \n",
       "1          2         Jessica Rios    clarkeashley@example.com            42   \n",
       "2          3  Christopher Robbins   gonzalestracy@example.com            48   \n",
       "\n",
       "  Customer Gender Product Purchased Date of Purchase      Ticket Type  \\\n",
       "0           Other        GoPro Hero       2021-03-22  Technical issue   \n",
       "1          Female       LG Smart TV       2021-05-22  Technical issue   \n",
       "2           Other          Dell XPS       2020-07-14  Technical issue   \n",
       "\n",
       "             Ticket Subject  \\\n",
       "0             Product setup   \n",
       "1  Peripheral compatibility   \n",
       "2           Network problem   \n",
       "\n",
       "                                  Ticket Description  \\\n",
       "0  I'm having an issue with the {product_purchase...   \n",
       "1  I'm having an issue with the {product_purchase...   \n",
       "2  I'm facing a problem with my {product_purchase...   \n",
       "\n",
       "               Ticket Status                                    Resolution  \\\n",
       "0  Pending Customer Response                                           NaN   \n",
       "1  Pending Customer Response                                           NaN   \n",
       "2                     Closed  Case maybe show recently my computer follow.   \n",
       "\n",
       "  Ticket Priority Ticket Channel  First Response Time   Time to Resolution  \\\n",
       "0        Critical   Social media  2023-06-01 12:15:36                  NaN   \n",
       "1        Critical           Chat  2023-06-01 16:45:38                  NaN   \n",
       "2             Low   Social media  2023-06-01 11:14:38  2023-06-01 18:05:38   \n",
       "\n",
       "   Customer Satisfaction Rating  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                           3.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"./customer_support_tickets.csv\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293feb7-0301-43c3-b2d3-03fb6f60e095",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31957763-0ca2-4f11-8b88-cb8306f72805",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "### Selecting appropriate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d370f8a-1b27-4403-907d-ea54ab1a5e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket Subject</th>\n",
       "      <th>Ticket Description</th>\n",
       "      <th>Ticket Priority</th>\n",
       "      <th>Ticket Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product setup</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Technical issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peripheral compatibility</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Technical issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Network problem</td>\n",
       "      <td>I'm facing a problem with my {product_purchase...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Technical issue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Ticket Subject  \\\n",
       "0             Product setup   \n",
       "1  Peripheral compatibility   \n",
       "2           Network problem   \n",
       "\n",
       "                                  Ticket Description Ticket Priority  \\\n",
       "0  I'm having an issue with the {product_purchase...        Critical   \n",
       "1  I'm having an issue with the {product_purchase...        Critical   \n",
       "2  I'm facing a problem with my {product_purchase...             Low   \n",
       "\n",
       "       Ticket Type  \n",
       "0  Technical issue  \n",
       "1  Technical issue  \n",
       "2  Technical issue  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legacy_cols = [\"Ticket Subject\", \"Ticket Description\", \"Ticket Priority\", \"Ticket Type\"] \n",
    "df = df[legacy_cols] \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3818c-c76f-4f6d-9f05-4d504a72280f",
   "metadata": {},
   "source": [
    "### Removing the {product_purchased} with a NULL value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8712e1f-fe13-421a-b134-2193a3be3537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Product setup | I'm having an issue with the [NULL]. Please assist.\\n\\nYour billing zip code is: 71701.\\n\\nWe appreciate that you have requested a website address.\\n\\nPlease double check your email address. I've tried troubleshooting steps mentioned in the user manual, but the issue persists.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Ticket Description\"] = df[\"Ticket Description\"].str.replace('{product_purchased}', '[NULL]')\n",
    "df[\"text\"] = df[\"Ticket Subject\"] + \" | \" + df[\"Ticket Description\"]\n",
    "df.drop(columns=[\"Ticket Subject\", \"Ticket Description\"], inplace=True)\n",
    "df[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf11b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(287.25162356830793), np.int64(149), np.int64(390))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lengths = df[\"text\"].str.len()\n",
    "average_length = text_lengths.mean()\n",
    "min_length = text_lengths.min()\n",
    "max_length = text_lengths.max()\n",
    "\n",
    "average_length, min_length, max_length\n",
    "\n",
    "#(np.float64(287.25162356830793), np.int64(149), np.int64(390)) max length should be 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7bd56f-6642-457e-9a12-a9f98a00e971",
   "metadata": {},
   "source": [
    "### Tokenization \n",
    "\n",
    "I utilize one-hot encoding here because we want CrossEntropy loss to compare the distributions.\n",
    "\n",
    "array([[1., 0., 0., 0.],\n",
    "       [1., 0., 0., 0.],\n",
    "       [0., 0., 1., 0.],\n",
    "       ...,\n",
    "       [0., 1., 0., 0.],\n",
    "       [0., 0., 0., 1.],\n",
    "       [0., 1., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27376e9d-a79f-4d06-9cc9-87200b1468e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision scikit-learn transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a50636-4b81-4c58-a335-11d307df5d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmcslarrow/Desktop/NORTHWESTERN/assignment-4-team/twitter_clone.env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6830887-7eac-4a92-87e1-0ea7d7058ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Critical', 'Low', 'High', 'Medium'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Ticket Priority\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ba4ac54-6b73-4987-bb5f-927c8f346df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Technical issue', 'Billing inquiry', 'Cancellation request',\n",
       "       'Product inquiry', 'Refund request'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Ticket Type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3d400-8a94-4cda-b145-3f2809282acf",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "\n",
    "#### Tokenization / Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4977149a-fd29-4d4f-97d3-0bb4374a82d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Critical', 1: 'Low', 2: 'High', 3: 'Medium'}\n",
      "{0: 'Technical issue', 1: 'Billing inquiry', 2: 'Cancellation request', 3: 'Product inquiry', 4: 'Refund request'}\n"
     ]
    }
   ],
   "source": [
    "# Mapping the labels to integers\n",
    "priority_map = {label: idx for idx, label in enumerate(df[\"Ticket Priority\"].unique())}\n",
    "type_map = {label: idx for idx, label in enumerate(df[\"Ticket Type\"].unique())}\n",
    "\n",
    "priority_map_idx_to_label = {idx: label for label, idx in priority_map.items()}\n",
    "type_map_idx_to_label = {idx: label for label, idx in type_map.items()}\n",
    "\n",
    "df[\"priority_label\"] = df[\"Ticket Priority\"].map(priority_map)\n",
    "df[\"type_label\"] = df[\"Ticket Type\"].map(type_map)\n",
    "\n",
    "# Tokenizing the text with BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized = tokenizer(list(df[\"text\"]), padding=True, truncation=True, return_tensors=\"pt\", max_length=400) # input_ids, attention_mask, token_type_ids\n",
    "\n",
    "print(priority_map_idx_to_label)\n",
    "print(type_map_idx_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29103071",
   "metadata": {},
   "source": [
    "#### Pytorch Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa525655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicketDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, priority_labels, type_labels):\n",
    "        self.encodings = encodings # tokenized\n",
    "        self.priority_labels = torch.tensor(priority_labels, dtype=torch.long)\n",
    "        self.type_labels = torch.tensor(type_labels, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"priority_labels\"] = self.priority_labels[idx]\n",
    "        item[\"type_labels\"] = self.type_labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.priority_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec5383d",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b9cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_encodings = tokenizer(list(train_df[\"text\"]), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "val_encodings = tokenizer(list(val_df[\"text\"]), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "train_dataset = TicketDataset(train_encodings, train_df[\"priority_label\"].tolist(), train_df[\"type_label\"].tolist())\n",
    "val_dataset = TicketDataset(val_encodings, val_df[\"priority_label\"].tolist(), val_df[\"type_label\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418e726",
   "metadata": {},
   "source": [
    "#### Printing a sample row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57e8ce61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'priority_labels', 'type_labels'])\n",
      "Priority Label (y1): 3 -->  Medium\n",
      "Type Label (y2): 2 -->  Cancellation request\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample = train_dataset[0]\n",
    "\n",
    "print(sample.keys())\n",
    "\n",
    "print(\"Priority Label (y1):\", sample[\"priority_labels\"].item(), \"--> \", priority_map_idx_to_label[sample[\"priority_labels\"].item()])\n",
    "print(\"Type Label (y2):\", sample[\"type_labels\"].item(), \"--> \", type_map_idx_to_label[sample[\"type_labels\"].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d091d",
   "metadata": {},
   "source": [
    "#### Multi-headed BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c214c1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n{0: 'Critical', 1: 'Low', 2: 'High', 3: 'Medium'}\\n{0: 'Technical issue', 1: 'Billing inquiry', 2: 'Cancellation request', 3: 'Product inquiry', 4: 'Refund request'}\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiTaskBERT(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_priorities=4, num_types=5):  \n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.priority_head = nn.Linear(hidden_size, num_priorities)\n",
    "        self.type_head = nn.Linear(hidden_size, num_types)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = self.dropout(outputs.pooler_output)\n",
    "        return self.priority_head(pooled), self.type_head(pooled)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "{0: 'Critical', 1: 'Low', 2: 'High', 3: 'Medium'}\n",
    "{0: 'Technical issue', 1: 'Billing inquiry', 2: 'Cancellation request', 3: 'Product inquiry', 4: 'Refund request'}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1872bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c71a4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiTaskBERT(num_priorities=4, num_types=5).to(device)  \n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e45822e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m loss2 = loss_fn(type_logits, type_labels)\n\u001b[32m     20\u001b[39m loss = loss1 + loss2\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m optimizer.step()\n\u001b[32m     25\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NORTHWESTERN/assignment-4-team/twitter_clone.env/lib/python3.13/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NORTHWESTERN/assignment-4-team/twitter_clone.env/lib/python3.13/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NORTHWESTERN/assignment-4-team/twitter_clone.env/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        priority_labels = batch[\"priority_labels\"].to(device)\n",
    "        type_labels = batch[\"type_labels\"].to(device)\n",
    "\n",
    "        priority_logits, type_logits = model(input_ids, attention_mask)\n",
    "\n",
    "        # priority_logits and type_logits will have shape (batch_size, num_priorities)\n",
    "        # we will utilize CrossEntropyLoss for both tasks\n",
    "\n",
    "        loss1 = loss_fn(priority_logits, priority_labels)\n",
    "        loss2 = loss_fn(type_logits, type_labels)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_clone.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
